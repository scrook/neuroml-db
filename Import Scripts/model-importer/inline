{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from manager import ModelManager\n",
    "from tables import Cells, Model_Waveforms, Models\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import pandas\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import hdbscan\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "pandas.set_option('display.max_columns', None)\n",
    "pandas.set_option('display.max_rows', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgr = ModelManager()\n",
    "mgr.server.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol_cost = {\n",
    "    'Steady State':       1, # 1s\n",
    "    'Standard':         5*2, # 5 repetitions of 1s SS 1s stim\n",
    "    'Strong':           5*2, # 5 repetitions of 1s SS 1s strong stim\n",
    "    'Input Resistance': 2*2, # 2 levels of 1s SS 1s stim\n",
    "}\n",
    "\n",
    "prop_protocol = {\n",
    "    'AP1Amplitude': 'Standard',\n",
    "    'AP2Amplitude': 'Standard',\n",
    "    'AP12AmplitudeDrop': 'Standard',\n",
    "    'AP12AmplitudeChangePercent': 'Standard',\n",
    "    'AP1SSAmplitudeChange': 'Standard'  ,\n",
    "    \n",
    "    'AP1WidthHalfHeight': 'Standard',\n",
    "    'AP2WidthHalfHeight': 'Standard',\n",
    "    'AP12HalfWidthChangePercent': 'Standard',\n",
    "    \n",
    "    'AP1WidthPeakToTrough': 'Standard',\n",
    "    'AP2WidthPeakToTrough': 'Standard',\n",
    "    \n",
    "    'AP1RateOfChangePeakToTrough': 'Standard',\n",
    "    'AP2RateOfChangePeakToTrough': 'Standard', \n",
    "    'AP12RateOfChangePeakToTroughPercentChange': 'Standard',\n",
    "    \n",
    "    'AP1AHPDepth': 'Standard',\n",
    "    'AP2AHPDepth': 'Standard',\n",
    "    'AP12AHPDepthPercentChange': 'Standard',\n",
    "    \n",
    "    'AP1DelayMean': 'Standard',\n",
    "    'AP2DelayMean': 'Standard',\n",
    "    \n",
    "    'AP1DelaySD': 'Standard',\n",
    "    'AP2DelaySD': 'Standard',\n",
    "    \n",
    "    'AP1DelayMeanStrongStim': 'Strong',\n",
    "    'AP2DelayMeanStrongStim': 'Strong',\n",
    "    \n",
    "    'AP1DelaySDStrongStim': 'Strong',\n",
    "    'AP2DelaySDStrongStim': 'Strong',\n",
    "    \n",
    "    'Burst1ISIMean': 'Standard',\n",
    "    'Burst1ISIMeanStrongStim': 'Strong',\n",
    "    \n",
    "    'Burst1ISISD': 'Standard',\n",
    "    'Burst1ISISDStrongStim': 'Strong',\n",
    "    \n",
    "    'InitialAccommodationMean': 'Standard',\n",
    "    'SSAccommodationMean': 'Standard',\n",
    "    'AccommodationRateToSS': 'Standard',\n",
    "    'AccommodationAtSSMean': 'Standard',\n",
    "    'AccommodationRateMeanAtSS': 'Standard',\n",
    "    \n",
    "    \n",
    "    'ISIMedian': 'Standard',\n",
    "    'ISICV': 'Standard',\n",
    "    'ISIBurstMeanChange': 'Standard',\n",
    "    \n",
    "    'SpikeRateStrongStim': 'Strong',\n",
    "    \n",
    "    'InputResistance': 'Input Resistance',\n",
    "    \n",
    "    'SteadyStateAPs': 'Steady State',\n",
    "}\n",
    "\n",
    "prop_names = [\n",
    "    'AP1Amplitude',\n",
    "    'AP2Amplitude',\n",
    "    'AP12AmplitudeDrop',\n",
    "    'AP12AmplitudeChangePercent',\n",
    "    'AP1SSAmplitudeChange',  \n",
    "    \n",
    "    'AP1WidthHalfHeight',\n",
    "    'AP2WidthHalfHeight',\n",
    "    'AP12HalfWidthChangePercent',\n",
    "    \n",
    "    'AP1WidthPeakToTrough',\n",
    "    'AP2WidthPeakToTrough',\n",
    "    \n",
    "    'AP1RateOfChangePeakToTrough',\n",
    "    'AP2RateOfChangePeakToTrough',    \n",
    "    'AP12RateOfChangePeakToTroughPercentChange',\n",
    "    \n",
    "    'AP1AHPDepth',\n",
    "    'AP2AHPDepth',\n",
    "    'AP12AHPDepthPercentChange',\n",
    "    \n",
    "    'AP1DelayMean',\n",
    "    'AP2DelayMean',\n",
    "    \n",
    "    'AP1DelaySD',\n",
    "    'AP2DelaySD',\n",
    "    \n",
    "    'AP1DelayMeanStrongStim',\n",
    "    'AP2DelayMeanStrongStim',\n",
    "    \n",
    "    'AP1DelaySDStrongStim',\n",
    "    'AP2DelaySDStrongStim',\n",
    "    \n",
    "    'Burst1ISIMean',\n",
    "    'Burst1ISIMeanStrongStim',\n",
    "    \n",
    "    'Burst1ISISD',\n",
    "    'Burst1ISISDStrongStim',\n",
    "    \n",
    "    'InitialAccommodationMean',\n",
    "    'SSAccommodationMean',\n",
    "    'AccommodationRateToSS',\n",
    "    'AccommodationAtSSMean',\n",
    "    'AccommodationRateMeanAtSS',\n",
    "    \n",
    "    \n",
    "    'ISIMedian',\n",
    "    'ISICV',\n",
    "    'ISIBurstMeanChange',\n",
    "    \n",
    "    'SpikeRateStrongStim',\n",
    "    \n",
    "    'InputResistance',\n",
    "    \n",
    "    'SteadyStateAPs',\n",
    "    \n",
    "    'FrequencyPassAbove',\n",
    "    'FrequencyPassBelow',\n",
    "    \n",
    "    'RampFirstSpike',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the remaining cell properties\n",
    "cells = list(Cells\\\n",
    "    .select(Cells,Model_Waveforms.Spikes,Models.Name)\\\n",
    "    .join(Model_Waveforms, on=(Cells.Model_ID == Model_Waveforms.Model_id))\\\n",
    "    .join(Models, on=(Cells.Model_ID == Models.Model_ID))\\\n",
    "    .where((Model_Waveforms.Protocol == \"STEADY_STATE\") & (Model_Waveforms.Variable_Name == \"Voltage\"))\\\n",
    "    .order_by(Cells.Model_ID)\n",
    "    .objects()\n",
    ")\n",
    "\n",
    "props = {}\n",
    "for c, cell in enumerate(cells):\n",
    "    for p, prop in enumerate(prop_names):\n",
    "        if prop not in props:\n",
    "            props[prop] = []\n",
    "        \n",
    "        if prop == 'SteadyStateAPs':\n",
    "            props[prop].append(cell.Spikes)\n",
    "            \n",
    "        else:\n",
    "            props[prop].append(getattr(cell, prop))\n",
    "        \n",
    "df = DataFrame(props, columns = prop_names)\n",
    "\n",
    "model_ids = [c.Model_ID for c in cells]        \n",
    "df.index = model_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AP1Amplitude'].fillna(0, inplace=True)\n",
    "df['AP2Amplitude'].fillna(0, inplace=True)\n",
    "\n",
    "df['AP1SSAmplitudeChange'].fillna(0, inplace=True)\n",
    "\n",
    "df['AP1WidthHalfHeight'].fillna(0, inplace=True)\n",
    "df['AP2WidthHalfHeight'].fillna(0, inplace=True)\n",
    "\n",
    "df['AP1WidthPeakToTrough'].fillna(0, inplace=True)\n",
    "df['AP2WidthPeakToTrough'].fillna(0, inplace=True)\n",
    "\n",
    "df['AP1RateOfChangePeakToTrough'].fillna(0, inplace=True)\n",
    "df['AP2RateOfChangePeakToTrough'].fillna(0, inplace=True)\n",
    "\n",
    "df['AP1AHPDepth'].fillna(0, inplace=True)\n",
    "df['AP2AHPDepth'].fillna(0, inplace=True)\n",
    "\n",
    "df['AP1DelayMean'].fillna(2000, inplace=True)\n",
    "df['AP2DelayMean'].fillna(2000, inplace=True)\n",
    "\n",
    "df['AP1DelaySD'].fillna(0, inplace=True)\n",
    "df['AP2DelaySD'].fillna(0, inplace=True)\n",
    "\n",
    "df['AP1DelayMeanStrongStim'].fillna(2000, inplace=True)\n",
    "df['AP2DelayMeanStrongStim'].fillna(2000, inplace=True)\n",
    "\n",
    "df['AP1DelaySDStrongStim'].fillna(0, inplace=True)\n",
    "df['AP2DelaySDStrongStim'].fillna(0, inplace=True)\n",
    "\n",
    "df['Burst1ISIMean'].fillna(2000, inplace=True)\n",
    "df['Burst1ISIMeanStrongStim'].fillna(2000, inplace=True)\n",
    "\n",
    "df['Burst1ISISD'].fillna(0, inplace=True)\n",
    "df['Burst1ISISDStrongStim'].fillna(0, inplace=True)\n",
    "\n",
    "df['AccommodationRateMeanAtSS'].fillna(2000, inplace=True)\n",
    "\n",
    "df['ISIMedian'].fillna(2000, inplace=True)\n",
    "\n",
    "df['ISICV'].fillna(0, inplace=True)\n",
    "\n",
    "df['ISIBurstMeanChange'].fillna(0, inplace=True)\n",
    "\n",
    "df['SpikeRateStrongStim'].fillna(0, inplace=True)\n",
    "\n",
    "df['InputResistance'].fillna(df['InputResistance'].mean(), inplace=True)\n",
    "\n",
    "df['FrequencyPassAbove'].fillna(29, inplace=True)\n",
    "df['FrequencyPassBelow'].fillna(143, inplace=True)\n",
    "\n",
    "df['RampFirstSpike'].fillna(5000, inplace=True)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    # No APs\n",
    "    if(row['AP1Amplitude'] == 0 and row['AP2Amplitude'] == 0):\n",
    "        df.at[index, 'AP12AmplitudeDrop'] = 0\n",
    "        df.at[index, 'AP12AmplitudeChangePercent'] = 0\n",
    "        df.at[index, 'AP1SSAmplitudeChange'] = 0\n",
    "        df.at[index, 'AP12HalfWidthChangePercent'] = 0\n",
    "        df.at[index, 'AP12RateOfChangePeakToTroughPercentChange'] = 0\n",
    "        df.at[index, 'AP12AHPDepthPercentChange'] = 0\n",
    "        df.at[index, 'InitialAccommodationMean'] = 0\n",
    "        df.at[index, 'SSAccommodationMean'] = 0\n",
    "        df.at[index, 'AccommodationRateToSS'] = 0\n",
    "        df.at[index, 'AccommodationAtSSMean'] = 0\n",
    "        \n",
    "    # Only 1 AP\n",
    "    if(row['AP1Amplitude'] > 0 and row['AP2Amplitude'] == 0):\n",
    "        df.at[index, 'AP12AmplitudeDrop'] = row['AP1Amplitude']\n",
    "        df.at[index, 'AP12AmplitudeChangePercent'] = -100\n",
    "        df.at[index, 'AP12HalfWidthChangePercent'] = -100\n",
    "        df.at[index, 'AP12RateOfChangePeakToTroughPercentChange'] = -100\n",
    "        df.at[index, 'AP12AHPDepthPercentChange'] = -100\n",
    "        df.at[index, 'AccommodationRateToSS'] = -1\n",
    "        df.at[index, 'AccommodationAtSSMean'] = -100\n",
    "    \n",
    "    # 1 AP and no SS APs\n",
    "    if row['AP1SSAmplitudeChange'] == 0 and row['AP1Amplitude'] > 0:\n",
    "        df.at[index, 'AP1SSAmplitudeChange'] = row['AP1Amplitude']\n",
    "            \n",
    "        \n",
    "    if np.isnan(row['AccommodationRateToSS']):\n",
    "        df.at[index, 'AccommodationRateToSS'] = -1\n",
    "        \n",
    "                \n",
    "    if np.isnan(row['AccommodationAtSSMean']):\n",
    "        df.at[index, 'AccommodationAtSSMean'] = -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_column(col):\n",
    "    # Bi-symmetric log-like transformation, from: \n",
    "    # http://iopscience.iop.org/article/10.1088/0957-0233/24/2/027001/pdf\n",
    "    trans = np.sign(df[col])*np.log(1+np.abs(df[col]*2.302585))\n",
    "    df[col] = trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_trans = DataFrame(df)\n",
    "\n",
    "log_column(\"AP12AmplitudeDrop\")\n",
    "log_column(\"AP12AmplitudeChangePercent\")\n",
    "log_column(\"AP1SSAmplitudeChange\")\n",
    "log_column(\"AP1WidthPeakToTrough\")\n",
    "log_column(\"AP2WidthPeakToTrough\")\n",
    "log_column(\"AP1RateOfChangePeakToTrough\")\n",
    "log_column(\"AP2RateOfChangePeakToTrough\")\n",
    "log_column(\"AP12RateOfChangePeakToTroughPercentChange\")\n",
    "log_column(\"AP12AHPDepthPercentChange\")\n",
    "log_column(\"AP1DelayMean\")\n",
    "log_column(\"AP2DelayMean\")\n",
    "log_column(\"AP1DelayMeanStrongStim\")\n",
    "log_column(\"AP2DelayMeanStrongStim\")\n",
    "log_column(\"Burst1ISIMean\")\n",
    "log_column(\"Burst1ISIMeanStrongStim\")\n",
    "log_column(\"AccommodationRateToSS\")\n",
    "log_column(\"AccommodationRateMeanAtSS\")\n",
    "log_column(\"ISIBurstMeanChange\")\n",
    "log_column(\"SpikeRateStrongStim\")\n",
    "log_column(\"InputResistance\")\n",
    "log_column(\"RampFirstSpike\")\n",
    "log_column(\"ISICV\")\n",
    "log_column(\"FrequencyPassAbove\")\n",
    "log_column(\"FrequencyPassBelow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"ClusterPath\"] = \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "ss = StandardScaler()\n",
    "x = ss.fit_transform(df.loc[:,prop_names].values)\n",
    "x = DataFrame(x,columns=prop_names)\n",
    "print('start dims', len(prop_names))\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(svd_solver='full',n_components=0.95)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalDf = DataFrame(data = principalComponents)\n",
    "X = principalDf\n",
    "X.index = df.index\n",
    "print('post-pca dims', len(principalDf.columns))\n",
    "print(X.shape[0],'rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = 0\n",
    "#col = \"AP12AmplitudeDrop\"\n",
    "#if col == \"AP12AmplitudeDrop\":\n",
    "for col in df.columns:\n",
    "    try:\n",
    "        if np.abs(pearsonr(X[pc],df[col])[0]) > 0:\n",
    "            plt.scatter(X[pc],df[col])\n",
    "            plt.title((col + str(pearsonr(X[pc],df[col]))))\n",
    "            plt.show();\n",
    "#             plt.scatter(X[pc],df_non_trans[col])\n",
    "#             plt.show();\n",
    "    except:\n",
    "        print('failed',col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = 0\n",
    "#col = \"AP12AmplitudeDrop\"\n",
    "#if col == \"AP12AmplitudeDrop\":\n",
    "for col in df.columns:\n",
    "    try:\n",
    "        if np.abs(pearsonr(X[pc],df[col])[0]) > 0:\n",
    "            plt.scatter(X[pc],df[col])\n",
    "            plt.title((col + str(pearsonr(X[pc],df[col]))))\n",
    "            plt.show();\n",
    "#             plt.scatter(X[pc],df_non_trans[col])\n",
    "#             plt.show();\n",
    "    except:\n",
    "        raise#print('failed',col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from manager import ModelManager\n",
    "from tables import Cells, Model_Waveforms, Models\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import pandas\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "import hdbscan\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "pandas.set_option('display.max_columns', None)\n",
    "pandas.set_option('display.max_rows', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = 0\n",
    "#col = \"AP12AmplitudeDrop\"\n",
    "#if col == \"AP12AmplitudeDrop\":\n",
    "for col in df.columns:\n",
    "    try:\n",
    "        if np.abs(pearsonr(X[pc],df[col])[0]) > 0:\n",
    "            plt.scatter(X[pc],df[col])\n",
    "            plt.title((col + str(pearsonr(X[pc],df[col]))))\n",
    "            plt.show();\n",
    "#             plt.scatter(X[pc],df_non_trans[col])\n",
    "#             plt.show();\n",
    "    except:\n",
    "        raise#print('failed',col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = 0\n",
    "#col = \"AP12AmplitudeDrop\"\n",
    "#if col == \"AP12AmplitudeDrop\":\n",
    "for col in df.columns:\n",
    "    try:\n",
    "        if np.abs(pearsonr(X[pc],df[col])[0]) > 0:\n",
    "            plt.scatter(X[pc],df[col])\n",
    "            plt.title((col + str(pearsonr(X[pc],df[col]))))\n",
    "            plt.show();\n",
    "#             plt.scatter(X[pc],df_non_trans[col])\n",
    "#             plt.show();\n",
    "    except:\n",
    "        print('failed',col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = 0\n",
    "#col = \"AP12AmplitudeDrop\"\n",
    "#if col == \"AP12AmplitudeDrop\":\n",
    "for col in df.columns:\n",
    "    try:\n",
    "        if np.abs(pearsonr(X[pc],df[col])[0]) >= 0:\n",
    "            plt.scatter(X[pc],df[col])\n",
    "            plt.title((col + str(pearsonr(X[pc],df[col]))))\n",
    "            plt.show();\n",
    "#             plt.scatter(X[pc],df_non_trans[col])\n",
    "#             plt.show();\n",
    "    except:\n",
    "        print('failed',col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_column(\"ISIMedian\")\n",
    "log_column(\"AP1WidthHalfHeight\")\n",
    "log_column(\"AP2WidthHalfHeight\")\n",
    "log_column(\"AP12HalfWidthChangePercent\")\n",
    "log_column(\"AP1AHPDepth\")\n",
    "log_column(\"AP2AHPDepth\")\n",
    "\n",
    "log_column(\"SteadyStateAPs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the remaining cell properties\n",
    "cells = list(Cells\\\n",
    "    .select(Cells,Model_Waveforms.Spikes,Models.Name)\\\n",
    "    .join(Model_Waveforms, on=(Cells.Model_ID == Model_Waveforms.Model_id))\\\n",
    "    .join(Models, on=(Cells.Model_ID == Models.Model_ID))\\\n",
    "    .where((Model_Waveforms.Protocol == \"STEADY_STATE\") & (Model_Waveforms.Variable_Name == \"Voltage\"))\\\n",
    "    .order_by(Cells.Model_ID)\n",
    "    .objects()\n",
    ")\n",
    "\n",
    "props = {}\n",
    "for c, cell in enumerate(cells):\n",
    "    for p, prop in enumerate(prop_names):\n",
    "        if prop not in props:\n",
    "            props[prop] = []\n",
    "        \n",
    "        if prop == 'SteadyStateAPs':\n",
    "            props[prop].append(cell.Spikes)\n",
    "            \n",
    "        else:\n",
    "            props[prop].append(getattr(cell, prop))\n",
    "        \n",
    "df = DataFrame(props, columns = prop_names)\n",
    "\n",
    "model_ids = [c.Model_ID for c in cells]        \n",
    "df.index = model_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AP1Amplitude'].fillna(0, inplace=True)\n",
    "df['AP2Amplitude'].fillna(0, inplace=True)\n",
    "\n",
    "df['AP1SSAmplitudeChange'].fillna(0, inplace=True)\n",
    "\n",
    "df['AP1WidthHalfHeight'].fillna(0, inplace=True)\n",
    "df['AP2WidthHalfHeight'].fillna(0, inplace=True)\n",
    "\n",
    "df['AP1WidthPeakToTrough'].fillna(0, inplace=True)\n",
    "df['AP2WidthPeakToTrough'].fillna(0, inplace=True)\n",
    "\n",
    "df['AP1RateOfChangePeakToTrough'].fillna(0, inplace=True)\n",
    "df['AP2RateOfChangePeakToTrough'].fillna(0, inplace=True)\n",
    "\n",
    "df['AP1AHPDepth'].fillna(0, inplace=True)\n",
    "df['AP2AHPDepth'].fillna(0, inplace=True)\n",
    "\n",
    "df['AP1DelayMean'].fillna(2000, inplace=True)\n",
    "df['AP2DelayMean'].fillna(2000, inplace=True)\n",
    "\n",
    "df['AP1DelaySD'].fillna(0, inplace=True)\n",
    "df['AP2DelaySD'].fillna(0, inplace=True)\n",
    "\n",
    "df['AP1DelayMeanStrongStim'].fillna(2000, inplace=True)\n",
    "df['AP2DelayMeanStrongStim'].fillna(2000, inplace=True)\n",
    "\n",
    "df['AP1DelaySDStrongStim'].fillna(0, inplace=True)\n",
    "df['AP2DelaySDStrongStim'].fillna(0, inplace=True)\n",
    "\n",
    "df['Burst1ISIMean'].fillna(2000, inplace=True)\n",
    "df['Burst1ISIMeanStrongStim'].fillna(2000, inplace=True)\n",
    "\n",
    "df['Burst1ISISD'].fillna(0, inplace=True)\n",
    "df['Burst1ISISDStrongStim'].fillna(0, inplace=True)\n",
    "\n",
    "df['AccommodationRateMeanAtSS'].fillna(2000, inplace=True)\n",
    "\n",
    "df['ISIMedian'].fillna(2000, inplace=True)\n",
    "\n",
    "df['ISICV'].fillna(0, inplace=True)\n",
    "\n",
    "df['ISIBurstMeanChange'].fillna(0, inplace=True)\n",
    "\n",
    "df['SpikeRateStrongStim'].fillna(0, inplace=True)\n",
    "\n",
    "df['InputResistance'].fillna(df['InputResistance'].mean(), inplace=True)\n",
    "\n",
    "df['FrequencyPassAbove'].fillna(29, inplace=True)\n",
    "df['FrequencyPassBelow'].fillna(143, inplace=True)\n",
    "\n",
    "df['RampFirstSpike'].fillna(5000, inplace=True)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    # No APs\n",
    "    if(row['AP1Amplitude'] == 0 and row['AP2Amplitude'] == 0):\n",
    "        df.at[index, 'AP12AmplitudeDrop'] = 0\n",
    "        df.at[index, 'AP12AmplitudeChangePercent'] = 0\n",
    "        df.at[index, 'AP1SSAmplitudeChange'] = 0\n",
    "        df.at[index, 'AP12HalfWidthChangePercent'] = 0\n",
    "        df.at[index, 'AP12RateOfChangePeakToTroughPercentChange'] = 0\n",
    "        df.at[index, 'AP12AHPDepthPercentChange'] = 0\n",
    "        df.at[index, 'InitialAccommodationMean'] = 0\n",
    "        df.at[index, 'SSAccommodationMean'] = 0\n",
    "        df.at[index, 'AccommodationRateToSS'] = 0\n",
    "        df.at[index, 'AccommodationAtSSMean'] = 0\n",
    "        \n",
    "    # Only 1 AP\n",
    "    if(row['AP1Amplitude'] > 0 and row['AP2Amplitude'] == 0):\n",
    "        df.at[index, 'AP12AmplitudeDrop'] = row['AP1Amplitude']\n",
    "        df.at[index, 'AP12AmplitudeChangePercent'] = -100\n",
    "        df.at[index, 'AP12HalfWidthChangePercent'] = -100\n",
    "        df.at[index, 'AP12RateOfChangePeakToTroughPercentChange'] = -100\n",
    "        df.at[index, 'AP12AHPDepthPercentChange'] = -100\n",
    "        df.at[index, 'AccommodationRateToSS'] = -1\n",
    "        df.at[index, 'AccommodationAtSSMean'] = -100\n",
    "    \n",
    "    # 1 AP and no SS APs\n",
    "    if row['AP1SSAmplitudeChange'] == 0 and row['AP1Amplitude'] > 0:\n",
    "        df.at[index, 'AP1SSAmplitudeChange'] = row['AP1Amplitude']\n",
    "            \n",
    "        \n",
    "    if np.isnan(row['AccommodationRateToSS']):\n",
    "        df.at[index, 'AccommodationRateToSS'] = -1\n",
    "        \n",
    "                \n",
    "    if np.isnan(row['AccommodationAtSSMean']):\n",
    "        df.at[index, 'AccommodationAtSSMean'] = -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_column(col):\n",
    "    # Bi-symmetric log-like transformation, from: \n",
    "    # http://iopscience.iop.org/article/10.1088/0957-0233/24/2/027001/pdf\n",
    "    trans = np.sign(df[col])*np.log(1+np.abs(df[col]*2.302585))\n",
    "    df[col] = trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_trans = DataFrame(df)\n",
    "\n",
    "log_column(\"AP12AmplitudeDrop\")\n",
    "log_column(\"AP12AmplitudeChangePercent\")\n",
    "log_column(\"AP1SSAmplitudeChange\")\n",
    "log_column(\"AP1WidthPeakToTrough\")\n",
    "log_column(\"AP2WidthPeakToTrough\")\n",
    "log_column(\"AP1RateOfChangePeakToTrough\")\n",
    "log_column(\"AP2RateOfChangePeakToTrough\")\n",
    "log_column(\"AP12RateOfChangePeakToTroughPercentChange\")\n",
    "log_column(\"AP12AHPDepthPercentChange\")\n",
    "log_column(\"AP1DelayMean\")\n",
    "log_column(\"AP2DelayMean\")\n",
    "log_column(\"AP1DelayMeanStrongStim\")\n",
    "log_column(\"AP2DelayMeanStrongStim\")\n",
    "log_column(\"Burst1ISIMean\")\n",
    "log_column(\"Burst1ISIMeanStrongStim\")\n",
    "log_column(\"AccommodationRateToSS\")\n",
    "log_column(\"AccommodationRateMeanAtSS\")\n",
    "log_column(\"ISIBurstMeanChange\")\n",
    "log_column(\"SpikeRateStrongStim\")\n",
    "log_column(\"InputResistance\")\n",
    "log_column(\"RampFirstSpike\")\n",
    "log_column(\"ISICV\")\n",
    "log_column(\"FrequencyPassAbove\")\n",
    "log_column(\"FrequencyPassBelow\")\n",
    "\n",
    "log_column(\"ISIMedian\")\n",
    "log_column(\"AP1WidthHalfHeight\")\n",
    "log_column(\"AP2WidthHalfHeight\")\n",
    "log_column(\"AP12HalfWidthChangePercent\")\n",
    "log_column(\"AP1AHPDepth\")\n",
    "log_column(\"AP2AHPDepth\")\n",
    "\n",
    "log_column(\"SteadyStateAPs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"ClusterPath\"] = \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df_all\n",
    "\n",
    "#df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/0/1/\")]\n",
    "\n",
    "# df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/0/\")]\n",
    "# df = df_all[df_all[\"Root_Cluster\"] == 0]\n",
    "# cluster_level = \"Multi-Spikers\" # 4 clusters\n",
    "\n",
    "# df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/0/0/\")]\n",
    "# df = df_all[df_all[\"Multi-Spikers\"] == 0] # 4 sub clusters - gain of 20  \n",
    "# cluster_level = \"Multi-Spikers-0\"\n",
    "\n",
    "#df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/0/0/0\")]\n",
    "#df = df_all[df_all[\"Multi-Spikers-0\"] == 0] \n",
    "#cluster_level = \"Multi-Spikers-0-0\"\n",
    "\n",
    "#df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/0/0/1\")]\n",
    "# df = df_all[df_all[\"Multi-Spikers-0\"] == 1] \n",
    "# cluster_level = \"Multi-Spikers-0-1\"\n",
    "\n",
    "#df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/0/0/2\")] # NO MORE SUBCLUSTERS\n",
    "#df = df_all[df_all[\"Multi-Spikers-0\"] == 2] \n",
    "#cluster_level = \"Multi-Spikers-0-2\"\n",
    "\n",
    "#df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/0/0/3\")] # NO MORE SUBCLUSTERS\n",
    "# df = df_all[df_all[\"Multi-Spikers-0\"] == 3]  \n",
    "# cluster_level = \"Multi-Spikers-0-3\"\n",
    "\n",
    "# df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/0/2/\")]\n",
    "# df = df_all[df_all[\"Multi-Spikers\"] == 2] # 2 sub clusters - gain of 17\n",
    "# cluster_level = \"Multi-Spikers-2\"\n",
    "\n",
    "# df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/0/1/\")]\n",
    "##df = df_all[df_all[\"Multi-Spikers\"] == 1]  # no gains from subclustering\n",
    "##cluster_level = \"Multi-Spikers-1\"\n",
    "\n",
    "# df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/0/3/\")]\n",
    "##df = df_all[df_all[\"Multi-Spikers\"] == 3]  # No gains from clustering further\n",
    "##cluster_level = \"Multi-Spikers-3\"\n",
    "\n",
    "#df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/0/1/3/\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "ss = StandardScaler()\n",
    "x = ss.fit_transform(df.loc[:,prop_names].values)\n",
    "x = DataFrame(x,columns=prop_names)\n",
    "print('start dims', len(prop_names))\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(svd_solver='full',n_components=0.95)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalDf = DataFrame(data = principalComponents)\n",
    "X = principalDf\n",
    "X.index = df.index\n",
    "print('post-pca dims', len(principalDf.columns))\n",
    "print(X.shape[0],'rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = 0\n",
    "#col = \"AP12AmplitudeDrop\"\n",
    "#if col == \"AP12AmplitudeDrop\":\n",
    "for col in df.columns:\n",
    "    try:\n",
    "        if np.abs(pearsonr(X[pc],df[col])[0]) >= 0:\n",
    "            plt.scatter(X[pc],df[col])\n",
    "            plt.title((col + str(pearsonr(X[pc],df[col]))))\n",
    "            plt.show();\n",
    "#             plt.scatter(X[pc],df_non_trans[col])\n",
    "#             plt.show();\n",
    "    except:\n",
    "        print('failed',col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from mpl_toolkits import mplot3d\n",
    "plt.figure(figsize=(15, 7))  \n",
    "plt.axes(projection='3d')\n",
    "plt.plot(X[0],X[1], X[2],'bo')\n",
    "plt.show()\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage  \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "linked = linkage(X, 'ward',optimal_ordering=False)\n",
    "\n",
    "plt.figure(figsize=(15, 7))  \n",
    "dendrogram(linked,  \n",
    "            orientation='top',\n",
    "            distance_sort='acending',\n",
    "            show_leaf_counts=True,\n",
    "            #truncate_mode='lastp',\n",
    "            #p=5,\n",
    "            show_contracted=True,\n",
    "          )\n",
    "plt.ylim(0,160)\n",
    "plt.show()  \n",
    "\n",
    "print(X.shape[0],'items')\n",
    "\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "range_n_clusters = range(2, 20)\n",
    "\n",
    "clusters = []\n",
    "widths = []\n",
    "for n_clusters in range_n_clusters:\n",
    "    from sklearn.cluster import AgglomerativeClustering\n",
    "    #clusterer = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "    clusterer = KMeans(n_clusters=n_clusters)  \n",
    "    cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        ith_cluster_silhouette_values = \\\n",
    "            sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "    \n",
    "    clusters.append(n_clusters)\n",
    "    widths.append(silhouette_avg)\n",
    "\n",
    "plt.plot(clusters, widths)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "i=0\n",
    "comp_names = []\n",
    "for i in range(3):\n",
    "    \n",
    "    comps = np.abs(pca.components_[i])\n",
    "    inds = (-comps).argsort()\n",
    "    plt.plot(range(len(pca.components_[0])), pca.components_[i][inds])\n",
    "    plt.show()\n",
    "    print(np.array(prop_names)[inds][:5])\n",
    "    print(pca.components_[i][inds][:5])\n",
    "    \n",
    "    name = \"\"\n",
    "    for f in range(3):\n",
    "        name += (\"-\" if pca.components_[i][inds][f] < 0 else \"+\") + prop_names[inds[f]]\n",
    "    comp_names.append(name)\n",
    "    print(name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "min_cluster_size=8\n",
    "n_clusters=3\n",
    "remove_noise = False\n",
    "\n",
    "k_means = True\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=1)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "    cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "    cluster.fit_predict(X) \n",
    "\n",
    "#     cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "#     cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(\n",
    "    X[cluster.labels_ != -1][0],\n",
    "    X[cluster.labels_ != -1][1], \n",
    "    X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "    c=cluster.labels_[cluster.labels_ != -1], \n",
    "    cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=8\n",
    "n_clusters=3\n",
    "remove_noise = False\n",
    "\n",
    "k_means = True\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=1)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "    cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "    cluster.fit_predict(X) \n",
    "\n",
    "#     cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "#     cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(\n",
    "    X[cluster.labels_ != -1][0],\n",
    "    X[cluster.labels_ != -1][1], \n",
    "    X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "    c=cluster.labels_[cluster.labels_ != -1], \n",
    "    cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=8\n",
    "n_clusters=3\n",
    "remove_noise = False\n",
    "\n",
    "k_means = False\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=1)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "    cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "    cluster.fit_predict(X) \n",
    "\n",
    "#     cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "#     cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(\n",
    "    X[cluster.labels_ != -1][0],\n",
    "    X[cluster.labels_ != -1][1], \n",
    "    X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "    c=cluster.labels_[cluster.labels_ != -1], \n",
    "    cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=8\n",
    "n_clusters=2\n",
    "remove_noise = False\n",
    "\n",
    "k_means = False\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=1)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "    cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "    cluster.fit_predict(X) \n",
    "\n",
    "#     cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "#     cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(\n",
    "    X[cluster.labels_ != -1][0],\n",
    "    X[cluster.labels_ != -1][1], \n",
    "    X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "    c=cluster.labels_[cluster.labels_ != -1], \n",
    "    cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=8\n",
    "n_clusters=2\n",
    "remove_noise = False\n",
    "\n",
    "k_means = False\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=1)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(\n",
    "    X[cluster.labels_ != -1][0],\n",
    "    X[cluster.labels_ != -1][1], \n",
    "    X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "    c=cluster.labels_[cluster.labels_ != -1], \n",
    "    cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=8\n",
    "n_clusters=4\n",
    "remove_noise = False\n",
    "\n",
    "k_means = True\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=1)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(\n",
    "    X[cluster.labels_ != -1][0],\n",
    "    X[cluster.labels_ != -1][1], \n",
    "    X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "    c=cluster.labels_[cluster.labels_ != -1], \n",
    "    cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=8\n",
    "n_clusters=4\n",
    "remove_noise = False\n",
    "\n",
    "k_means = True\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=1)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(\n",
    "    X[cluster.labels_ != -1][0],\n",
    "    X[cluster.labels_ != -1][1], \n",
    "    X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "    c=cluster.labels_[cluster.labels_ != -1], \n",
    "    cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=8\n",
    "n_clusters=4\n",
    "remove_noise = False\n",
    "\n",
    "k_means = True\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=1)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(\n",
    "    X[cluster.labels_ != -1][0],\n",
    "    X[cluster.labels_ != -1][1], \n",
    "    X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "    c=cluster.labels_[cluster.labels_ != -1], \n",
    "    cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=8\n",
    "n_clusters=3\n",
    "remove_noise = False\n",
    "\n",
    "k_means = True\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=1)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(\n",
    "    X[cluster.labels_ != -1][0],\n",
    "    X[cluster.labels_ != -1][1], \n",
    "    X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "    c=cluster.labels_[cluster.labels_ != -1], \n",
    "    cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=8\n",
    "n_clusters=3\n",
    "remove_noise = False\n",
    "\n",
    "k_means = True\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(\n",
    "    X[cluster.labels_ != -1][0],\n",
    "    X[cluster.labels_ != -1][1], \n",
    "    X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "    c=cluster.labels_[cluster.labels_ != -1], \n",
    "    cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=10\n",
    "n_clusters=3\n",
    "remove_noise = False\n",
    "\n",
    "k_means = False\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(\n",
    "    X[cluster.labels_ != -1][0],\n",
    "    X[cluster.labels_ != -1][1], \n",
    "    X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "    c=cluster.labels_[cluster.labels_ != -1], \n",
    "    cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=5\n",
    "n_clusters=3\n",
    "remove_noise = False\n",
    "\n",
    "k_means = False\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(\n",
    "    X[cluster.labels_ != -1][0],\n",
    "    X[cluster.labels_ != -1][1], \n",
    "    X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "    c=cluster.labels_[cluster.labels_ != -1], \n",
    "    cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=9\n",
    "n_clusters=3\n",
    "remove_noise = False\n",
    "\n",
    "k_means = False\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(\n",
    "    X[cluster.labels_ != -1][0],\n",
    "    X[cluster.labels_ != -1][1], \n",
    "    X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "    c=cluster.labels_[cluster.labels_ != -1], \n",
    "    cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=10\n",
    "n_clusters=3\n",
    "remove_noise = False\n",
    "\n",
    "k_means = False\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(\n",
    "    X[cluster.labels_ != -1][0],\n",
    "    X[cluster.labels_ != -1][1], \n",
    "    X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "    c=cluster.labels_[cluster.labels_ != -1], \n",
    "    cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=12\n",
    "n_clusters=3\n",
    "remove_noise = False\n",
    "\n",
    "k_means = False\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(\n",
    "    X[cluster.labels_ != -1][0],\n",
    "    X[cluster.labels_ != -1][1], \n",
    "    X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "    c=cluster.labels_[cluster.labels_ != -1], \n",
    "    cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=12\n",
    "n_clusters=3\n",
    "remove_noise = False\n",
    "\n",
    "k_means = False\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(\n",
    "    X[cluster.labels_ != -1][0],\n",
    "    X[cluster.labels_ != -1][1], \n",
    "    X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "    c=cluster.labels_[cluster.labels_ != -1], \n",
    "    cmap='flag')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=12\n",
    "n_clusters=3\n",
    "remove_noise = False\n",
    "\n",
    "k_means = False\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.scatter(\n",
    "#     X[cluster.labels_ != -1][0],\n",
    "#     X[cluster.labels_ != -1][1], \n",
    "#     X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "#     c=cluster.labels_[cluster.labels_ != -1], \n",
    "#     cmap='flag')\n",
    "\n",
    "ax.scatter(\n",
    "    X[0],\n",
    "    X[1], \n",
    "    X[2], depthshade=False,marker='o', \n",
    "    c=cluster.labels_, \n",
    "    cmap='flag')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=11\n",
    "n_clusters=3\n",
    "remove_noise = False\n",
    "\n",
    "k_means = False\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.scatter(\n",
    "#     X[cluster.labels_ != -1][0],\n",
    "#     X[cluster.labels_ != -1][1], \n",
    "#     X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "#     c=cluster.labels_[cluster.labels_ != -1], \n",
    "#     cmap='flag')\n",
    "\n",
    "ax.scatter(\n",
    "    X[0],\n",
    "    X[1], \n",
    "    X[2], depthshade=False,marker='o', \n",
    "    c=cluster.labels_, \n",
    "    cmap='flag')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=11\n",
    "n_clusters=3\n",
    "remove_noise = False\n",
    "\n",
    "k_means = False\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.scatter(\n",
    "#     X[cluster.labels_ != -1][0],\n",
    "#     X[cluster.labels_ != -1][1], \n",
    "#     X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "#     c=cluster.labels_[cluster.labels_ != -1], \n",
    "#     cmap='flag')\n",
    "\n",
    "ax.scatter(\n",
    "    X[0],\n",
    "    X[1], \n",
    "    X[2], depthshade=False,marker='o', \n",
    "    c=cluster.labels_, \n",
    "    cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=10\n",
    "n_clusters=3\n",
    "remove_noise = False\n",
    "\n",
    "k_means = False\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.scatter(\n",
    "#     X[cluster.labels_ != -1][0],\n",
    "#     X[cluster.labels_ != -1][1], \n",
    "#     X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "#     c=cluster.labels_[cluster.labels_ != -1], \n",
    "#     cmap='flag')\n",
    "\n",
    "ax.scatter(\n",
    "    X[0],\n",
    "    X[1], \n",
    "    X[2], depthshade=False,marker='o', \n",
    "    c=cluster.labels_, \n",
    "    cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=11\n",
    "n_clusters=3\n",
    "remove_noise = False\n",
    "\n",
    "k_means = False\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.scatter(\n",
    "#     X[cluster.labels_ != -1][0],\n",
    "#     X[cluster.labels_ != -1][1], \n",
    "#     X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "#     c=cluster.labels_[cluster.labels_ != -1], \n",
    "#     cmap='flag')\n",
    "\n",
    "ax.scatter(\n",
    "    X[0],\n",
    "    X[1], \n",
    "    X[2], depthshade=False,marker='o', \n",
    "    c=cluster.labels_, \n",
    "    cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=11\n",
    "n_clusters=2\n",
    "remove_noise = False\n",
    "\n",
    "k_means = True\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.scatter(\n",
    "#     X[cluster.labels_ != -1][0],\n",
    "#     X[cluster.labels_ != -1][1], \n",
    "#     X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "#     c=cluster.labels_[cluster.labels_ != -1], \n",
    "#     cmap='flag')\n",
    "\n",
    "ax.scatter(\n",
    "    X[0],\n",
    "    X[1], \n",
    "    X[2], depthshade=False,marker='o', \n",
    "    c=cluster.labels_, \n",
    "    cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ClusterPath\"] = \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set subset df cluster\n",
    "df[\"Cluster\"] = cluster.labels_\n",
    "\n",
    "df[\"ClusterPath\"] = df[\"ClusterPath\"] + df[\"Cluster\"].map(str) + \"/\"\n",
    "\n",
    "for label in df.index:\n",
    "    df_all.at[label, \"ClusterPath\"] = df.at[label, \"ClusterPath\"]\n",
    "    df_all.at[label, \"Cluster\"] = df.at[label, \"Cluster\"]\n",
    "\n",
    "df.head()[\"ClusterPath\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head()[\"ClusterPath\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df_all\n",
    "\n",
    "df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/1/\")]\n",
    "\n",
    "# df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/0/\")]\n",
    "# df = df_all[df_all[\"Root_Cluster\"] == 0]\n",
    "# cluster_level = \"Multi-Spikers\" # 4 clusters\n",
    "\n",
    "# df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/0/0/\")]\n",
    "# df = df_all[df_all[\"Multi-Spikers\"] == 0] # 4 sub clusters - gain of 20  \n",
    "# cluster_level = \"Multi-Spikers-0\"\n",
    "\n",
    "#df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/0/0/0\")]\n",
    "#df = df_all[df_all[\"Multi-Spikers-0\"] == 0] \n",
    "#cluster_level = \"Multi-Spikers-0-0\"\n",
    "\n",
    "#df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/0/0/1\")]\n",
    "# df = df_all[df_all[\"Multi-Spikers-0\"] == 1] \n",
    "# cluster_level = \"Multi-Spikers-0-1\"\n",
    "\n",
    "#df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/0/0/2\")] # NO MORE SUBCLUSTERS\n",
    "#df = df_all[df_all[\"Multi-Spikers-0\"] == 2] \n",
    "#cluster_level = \"Multi-Spikers-0-2\"\n",
    "\n",
    "#df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/0/0/3\")] # NO MORE SUBCLUSTERS\n",
    "# df = df_all[df_all[\"Multi-Spikers-0\"] == 3]  \n",
    "# cluster_level = \"Multi-Spikers-0-3\"\n",
    "\n",
    "# df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/0/2/\")]\n",
    "# df = df_all[df_all[\"Multi-Spikers\"] == 2] # 2 sub clusters - gain of 17\n",
    "# cluster_level = \"Multi-Spikers-2\"\n",
    "\n",
    "# df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/0/1/\")]\n",
    "##df = df_all[df_all[\"Multi-Spikers\"] == 1]  # no gains from subclustering\n",
    "##cluster_level = \"Multi-Spikers-1\"\n",
    "\n",
    "# df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/0/3/\")]\n",
    "##df = df_all[df_all[\"Multi-Spikers\"] == 3]  # No gains from clustering further\n",
    "##cluster_level = \"Multi-Spikers-3\"\n",
    "\n",
    "#df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/0/1/3/\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "ss = StandardScaler()\n",
    "x = ss.fit_transform(df.loc[:,prop_names].values)\n",
    "x = DataFrame(x,columns=prop_names)\n",
    "print('start dims', len(prop_names))\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(svd_solver='full',n_components=0.95)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalDf = DataFrame(data = principalComponents)\n",
    "X = principalDf\n",
    "X.index = df.index\n",
    "print('post-pca dims', len(principalDf.columns))\n",
    "print(X.shape[0],'rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = 0\n",
    "#col = \"AP12AmplitudeDrop\"\n",
    "#if col == \"AP12AmplitudeDrop\":\n",
    "for col in df.columns:\n",
    "    try:\n",
    "        if np.abs(pearsonr(X[pc],df[col])[0]) >= 0:\n",
    "            plt.scatter(X[pc],df[col])\n",
    "            plt.title((col + str(pearsonr(X[pc],df[col]))))\n",
    "            plt.show();\n",
    "#             plt.scatter(X[pc],df_non_trans[col])\n",
    "#             plt.show();\n",
    "    except:\n",
    "        print('failed',col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = 0\n",
    "#col = \"AP12AmplitudeDrop\"\n",
    "#if col == \"AP12AmplitudeDrop\":\n",
    "for col in df.columns:\n",
    "    try:\n",
    "        if np.abs(pearsonr(X[pc],df[col])[0]) >= 0:\n",
    "            plt.scatter(X[pc],df[col])\n",
    "            plt.title((col + str(pearsonr(X[pc],df[col]))))\n",
    "            plt.show();\n",
    "#             plt.scatter(X[pc],df_non_trans[col])\n",
    "#             plt.show();\n",
    "    except:\n",
    "        raise#print('failed',col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = 0\n",
    "#col = \"AP12AmplitudeDrop\"\n",
    "#if col == \"AP12AmplitudeDrop\":\n",
    "for col in df.columns:\n",
    "    try:\n",
    "        if np.abs(pearsonr(X[pc],df[col])[0]) >= 0:\n",
    "            plt.scatter(X[pc],df[col])\n",
    "            #plt.title((col + str(pearsonr(X[pc],df[col]))))\n",
    "            plt.show();\n",
    "#             plt.scatter(X[pc],df_non_trans[col])\n",
    "#             plt.show();\n",
    "    except:\n",
    "        raise#print('failed',col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[pc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[pc],df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.scatter(X[pc],df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = 0\n",
    "#col = \"AP12AmplitudeDrop\"\n",
    "#if col == \"AP12AmplitudeDrop\":\n",
    "for col in df.columns:\n",
    "    try:\n",
    "        if np.abs(pearsonr(X[pc],df[col])[0]) >= 0:\n",
    "            plt.scatter(X[pc],df[col])\n",
    "            #plt.title((col + str(pearsonr(X[pc],df[col]))))\n",
    "            plt.show();\n",
    "#             plt.scatter(X[pc],df_non_trans[col])\n",
    "#             plt.show();\n",
    "    except:\n",
    "        raise#print('failed',col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = 0\n",
    "#col = \"AP12AmplitudeDrop\"\n",
    "#if col == \"AP12AmplitudeDrop\":\n",
    "for col in df.columns:\n",
    "    try:\n",
    "        if np.abs(pearsonr(X[pc],df[col])[0]) >= 0:\n",
    "            plt.scatter(X[pc],df[col])\n",
    "            #plt.title((col + str(pearsonr(X[pc],df[col]))))\n",
    "            plt.show();\n",
    "#             plt.scatter(X[pc],df_non_trans[col])\n",
    "#             plt.show();\n",
    "    except:\n",
    "        print('failed',col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from mpl_toolkits import mplot3d\n",
    "plt.figure(figsize=(15, 7))  \n",
    "plt.axes(projection='3d')\n",
    "plt.plot(X[0],X[1], X[2],'bo')\n",
    "plt.show()\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage  \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "linked = linkage(X, 'ward',optimal_ordering=False)\n",
    "\n",
    "plt.figure(figsize=(15, 7))  \n",
    "dendrogram(linked,  \n",
    "            orientation='top',\n",
    "            distance_sort='acending',\n",
    "            show_leaf_counts=True,\n",
    "            #truncate_mode='lastp',\n",
    "            #p=5,\n",
    "            show_contracted=True,\n",
    "          )\n",
    "plt.ylim(0,160)\n",
    "plt.show()  \n",
    "\n",
    "print(X.shape[0],'items')\n",
    "\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "range_n_clusters = range(2, 20)\n",
    "\n",
    "clusters = []\n",
    "widths = []\n",
    "for n_clusters in range_n_clusters:\n",
    "    from sklearn.cluster import AgglomerativeClustering\n",
    "    #clusterer = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "    clusterer = KMeans(n_clusters=n_clusters)  \n",
    "    cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        ith_cluster_silhouette_values = \\\n",
    "            sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "    \n",
    "    clusters.append(n_clusters)\n",
    "    widths.append(silhouette_avg)\n",
    "\n",
    "plt.plot(clusters, widths)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "i=0\n",
    "comp_names = []\n",
    "for i in range(3):\n",
    "    \n",
    "    comps = np.abs(pca.components_[i])\n",
    "    inds = (-comps).argsort()\n",
    "    plt.plot(range(len(pca.components_[0])), pca.components_[i][inds])\n",
    "    plt.show()\n",
    "    print(np.array(prop_names)[inds][:5])\n",
    "    print(pca.components_[i][inds][:5])\n",
    "    \n",
    "    name = \"\"\n",
    "    for f in range(3):\n",
    "        name += (\"-\" if pca.components_[i][inds][f] < 0 else \"+\") + prop_names[inds[f]]\n",
    "    comp_names.append(name)\n",
    "    print(name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=11\n",
    "n_clusters=2\n",
    "remove_noise = False\n",
    "\n",
    "k_means = True\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.scatter(\n",
    "#     X[cluster.labels_ != -1][0],\n",
    "#     X[cluster.labels_ != -1][1], \n",
    "#     X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "#     c=cluster.labels_[cluster.labels_ != -1], \n",
    "#     cmap='flag')\n",
    "\n",
    "ax.scatter(\n",
    "    X[0],\n",
    "    X[1], \n",
    "    X[2], depthshade=False,marker='o', \n",
    "    c=cluster.labels_, \n",
    "    cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=11\n",
    "n_clusters=2\n",
    "remove_noise = False\n",
    "\n",
    "k_means = True\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.scatter(\n",
    "#     X[cluster.labels_ != -1][0],\n",
    "#     X[cluster.labels_ != -1][1], \n",
    "#     X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "#     c=cluster.labels_[cluster.labels_ != -1], \n",
    "#     cmap='flag')\n",
    "\n",
    "ax.scatter(\n",
    "    X[0],\n",
    "    X[1], \n",
    "    X[2], depthshade=False,marker='o', \n",
    "    c=cluster.labels_, \n",
    "    cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=11\n",
    "n_clusters=2\n",
    "hide_noise = True\n",
    "remove_noise = False\n",
    "k_means = False\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "if hide_noise:\n",
    "    ax.scatter(\n",
    "        X[cluster.labels_ != -1][0],\n",
    "        X[cluster.labels_ != -1][1], \n",
    "        X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_[cluster.labels_ != -1], \n",
    "        cmap='flag')\n",
    "else:\n",
    "    ax.scatter(\n",
    "        X[0],\n",
    "        X[1], \n",
    "        X[2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_, \n",
    "        cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=11\n",
    "n_clusters=2\n",
    "hide_noise = False\n",
    "remove_noise = False\n",
    "k_means = False\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "if hide_noise:\n",
    "    ax.scatter(\n",
    "        X[cluster.labels_ != -1][0],\n",
    "        X[cluster.labels_ != -1][1], \n",
    "        X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_[cluster.labels_ != -1], \n",
    "        cmap='flag')\n",
    "else:\n",
    "    ax.scatter(\n",
    "        X[0],\n",
    "        X[1], \n",
    "        X[2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_, \n",
    "        cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=10\n",
    "n_clusters=2\n",
    "hide_noise = False\n",
    "remove_noise = False\n",
    "k_means = False\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "if hide_noise:\n",
    "    ax.scatter(\n",
    "        X[cluster.labels_ != -1][0],\n",
    "        X[cluster.labels_ != -1][1], \n",
    "        X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_[cluster.labels_ != -1], \n",
    "        cmap='flag')\n",
    "else:\n",
    "    ax.scatter(\n",
    "        X[0],\n",
    "        X[1], \n",
    "        X[2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_, \n",
    "        cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=11\n",
    "n_clusters=2\n",
    "hide_noise = False\n",
    "remove_noise = False\n",
    "k_means = False\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "if hide_noise:\n",
    "    ax.scatter(\n",
    "        X[cluster.labels_ != -1][0],\n",
    "        X[cluster.labels_ != -1][1], \n",
    "        X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_[cluster.labels_ != -1], \n",
    "        cmap='flag')\n",
    "else:\n",
    "    ax.scatter(\n",
    "        X[0],\n",
    "        X[1], \n",
    "        X[2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_, \n",
    "        cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set subset df cluster\n",
    "df[\"Cluster\"] = cluster.labels_\n",
    "\n",
    "df[\"ClusterPath\"] = df[\"ClusterPath\"] + df[\"Cluster\"].map(str) + \"/\"\n",
    "\n",
    "for label in df.index:\n",
    "    df_all.at[label, \"ClusterPath\"] = df.at[label, \"ClusterPath\"]\n",
    "    df_all.at[label, \"Cluster\"] = df.at[label, \"Cluster\"]\n",
    "\n",
    "df.head()[\"ClusterPath\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head()[\"ClusterPath\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df_all\n",
    "\n",
    "df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/1/1/\")]\n",
    "\n",
    "# df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/0/\")]\n",
    "# df = df_all[df_all[\"Root_Cluster\"] == 0]\n",
    "# cluster_level = \"Multi-Spikers\" # 4 clusters\n",
    "\n",
    "# df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/0/0/\")]\n",
    "# df = df_all[df_all[\"Multi-Spikers\"] == 0] # 4 sub clusters - gain of 20  \n",
    "# cluster_level = \"Multi-Spikers-0\"\n",
    "\n",
    "#df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/0/0/0\")]\n",
    "#df = df_all[df_all[\"Multi-Spikers-0\"] == 0] \n",
    "#cluster_level = \"Multi-Spikers-0-0\"\n",
    "\n",
    "#df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/0/0/1\")]\n",
    "# df = df_all[df_all[\"Multi-Spikers-0\"] == 1] \n",
    "# cluster_level = \"Multi-Spikers-0-1\"\n",
    "\n",
    "#df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/0/0/2\")] # NO MORE SUBCLUSTERS\n",
    "#df = df_all[df_all[\"Multi-Spikers-0\"] == 2] \n",
    "#cluster_level = \"Multi-Spikers-0-2\"\n",
    "\n",
    "#df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/0/0/3\")] # NO MORE SUBCLUSTERS\n",
    "# df = df_all[df_all[\"Multi-Spikers-0\"] == 3]  \n",
    "# cluster_level = \"Multi-Spikers-0-3\"\n",
    "\n",
    "# df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/0/2/\")]\n",
    "# df = df_all[df_all[\"Multi-Spikers\"] == 2] # 2 sub clusters - gain of 17\n",
    "# cluster_level = \"Multi-Spikers-2\"\n",
    "\n",
    "# df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/0/1/\")]\n",
    "##df = df_all[df_all[\"Multi-Spikers\"] == 1]  # no gains from subclustering\n",
    "##cluster_level = \"Multi-Spikers-1\"\n",
    "\n",
    "# df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/0/3/\")]\n",
    "##df = df_all[df_all[\"Multi-Spikers\"] == 3]  # No gains from clustering further\n",
    "##cluster_level = \"Multi-Spikers-3\"\n",
    "\n",
    "#df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/0/1/3/\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "ss = StandardScaler()\n",
    "x = ss.fit_transform(df.loc[:,prop_names].values)\n",
    "x = DataFrame(x,columns=prop_names)\n",
    "print('start dims', len(prop_names))\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(svd_solver='full',n_components=0.95)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalDf = DataFrame(data = principalComponents)\n",
    "X = principalDf\n",
    "X.index = df.index\n",
    "print('post-pca dims', len(principalDf.columns))\n",
    "print(X.shape[0],'rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = 0\n",
    "#col = \"AP12AmplitudeDrop\"\n",
    "#if col == \"AP12AmplitudeDrop\":\n",
    "for col in df.columns:\n",
    "    try:\n",
    "        if np.abs(pearsonr(X[pc],df[col])[0]) >= 0:\n",
    "            plt.scatter(X[pc],df[col])\n",
    "            #plt.title((col + str(pearsonr(X[pc],df[col]))))\n",
    "            plt.show();\n",
    "#             plt.scatter(X[pc],df_non_trans[col])\n",
    "#             plt.show();\n",
    "    except:\n",
    "        print('failed',col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = 0\n",
    "#col = \"AP12AmplitudeDrop\"\n",
    "#if col == \"AP12AmplitudeDrop\":\n",
    "for col in df.columns:\n",
    "    try:\n",
    "        if np.abs(pearsonr(X[pc],df[col])[0]) >= 0:\n",
    "            plt.scatter(X[pc],df[col])\n",
    "            plt.title((col + str(pearsonr(X[pc],df[col]))))\n",
    "            plt.show();\n",
    "#             plt.scatter(X[pc],df_non_trans[col])\n",
    "#             plt.show();\n",
    "    except:\n",
    "        print('failed',col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from mpl_toolkits import mplot3d\n",
    "plt.figure(figsize=(15, 7))  \n",
    "plt.axes(projection='3d')\n",
    "plt.plot(X[0],X[1], X[2],'bo')\n",
    "plt.show()\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage  \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "linked = linkage(X, 'ward',optimal_ordering=False)\n",
    "\n",
    "plt.figure(figsize=(15, 7))  \n",
    "dendrogram(linked,  \n",
    "            orientation='top',\n",
    "            distance_sort='acending',\n",
    "            show_leaf_counts=True,\n",
    "            #truncate_mode='lastp',\n",
    "            #p=5,\n",
    "            show_contracted=True,\n",
    "          )\n",
    "plt.ylim(0,160)\n",
    "plt.show()  \n",
    "\n",
    "print(X.shape[0],'items')\n",
    "\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "range_n_clusters = range(2, 20)\n",
    "\n",
    "clusters = []\n",
    "widths = []\n",
    "for n_clusters in range_n_clusters:\n",
    "    from sklearn.cluster import AgglomerativeClustering\n",
    "    #clusterer = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "    clusterer = KMeans(n_clusters=n_clusters)  \n",
    "    cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        ith_cluster_silhouette_values = \\\n",
    "            sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "    \n",
    "    clusters.append(n_clusters)\n",
    "    widths.append(silhouette_avg)\n",
    "\n",
    "plt.plot(clusters, widths)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "i=0\n",
    "comp_names = []\n",
    "for i in range(3):\n",
    "    \n",
    "    comps = np.abs(pca.components_[i])\n",
    "    inds = (-comps).argsort()\n",
    "    plt.plot(range(len(pca.components_[0])), pca.components_[i][inds])\n",
    "    plt.show()\n",
    "    print(np.array(prop_names)[inds][:5])\n",
    "    print(pca.components_[i][inds][:5])\n",
    "    \n",
    "    name = \"\"\n",
    "    for f in range(3):\n",
    "        name += (\"-\" if pca.components_[i][inds][f] < 0 else \"+\") + prop_names[inds[f]]\n",
    "    comp_names.append(name)\n",
    "    print(name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=11\n",
    "n_clusters=2\n",
    "hide_noise = False\n",
    "remove_noise = False\n",
    "k_means = False\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "if hide_noise:\n",
    "    ax.scatter(\n",
    "        X[cluster.labels_ != -1][0],\n",
    "        X[cluster.labels_ != -1][1], \n",
    "        X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_[cluster.labels_ != -1], \n",
    "        cmap='flag')\n",
    "else:\n",
    "    ax.scatter(\n",
    "        X[0],\n",
    "        X[1], \n",
    "        X[2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_, \n",
    "        cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=11\n",
    "n_clusters=2\n",
    "hide_noise = False\n",
    "remove_noise = False\n",
    "k_means = False\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "if hide_noise:\n",
    "    ax.scatter(\n",
    "        X[cluster.labels_ != -1][0],\n",
    "        X[cluster.labels_ != -1][1], \n",
    "        X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_[cluster.labels_ != -1], \n",
    "        cmap='flag')\n",
    "else:\n",
    "    ax.scatter(\n",
    "        X[0],\n",
    "        X[1], \n",
    "        X[2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_, \n",
    "        cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=11\n",
    "n_clusters=2\n",
    "hide_noise = True\n",
    "remove_noise = False\n",
    "k_means = False\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "if hide_noise:\n",
    "    ax.scatter(\n",
    "        X[cluster.labels_ != -1][0],\n",
    "        X[cluster.labels_ != -1][1], \n",
    "        X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_[cluster.labels_ != -1], \n",
    "        cmap='flag')\n",
    "else:\n",
    "    ax.scatter(\n",
    "        X[0],\n",
    "        X[1], \n",
    "        X[2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_, \n",
    "        cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=11\n",
    "n_clusters=2\n",
    "hide_noise = False\n",
    "remove_noise = False\n",
    "k_means = True\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "if hide_noise:\n",
    "    ax.scatter(\n",
    "        X[cluster.labels_ != -1][0],\n",
    "        X[cluster.labels_ != -1][1], \n",
    "        X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_[cluster.labels_ != -1], \n",
    "        cmap='flag')\n",
    "else:\n",
    "    ax.scatter(\n",
    "        X[0],\n",
    "        X[1], \n",
    "        X[2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_, \n",
    "        cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=11\n",
    "n_clusters=7\n",
    "hide_noise = False\n",
    "remove_noise = False\n",
    "k_means = True\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "if hide_noise:\n",
    "    ax.scatter(\n",
    "        X[cluster.labels_ != -1][0],\n",
    "        X[cluster.labels_ != -1][1], \n",
    "        X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_[cluster.labels_ != -1], \n",
    "        cmap='flag')\n",
    "else:\n",
    "    ax.scatter(\n",
    "        X[0],\n",
    "        X[1], \n",
    "        X[2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_, \n",
    "        cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=11\n",
    "n_clusters=7\n",
    "hide_noise = False\n",
    "remove_noise = False\n",
    "k_means = False\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "    cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "    cluster.fit_predict(X) \n",
    "\n",
    "#     cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "#     cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "if hide_noise:\n",
    "    ax.scatter(\n",
    "        X[cluster.labels_ != -1][0],\n",
    "        X[cluster.labels_ != -1][1], \n",
    "        X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_[cluster.labels_ != -1], \n",
    "        cmap='flag')\n",
    "else:\n",
    "    ax.scatter(\n",
    "        X[0],\n",
    "        X[1], \n",
    "        X[2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_, \n",
    "        cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=10\n",
    "n_clusters=7\n",
    "hide_noise = False\n",
    "remove_noise = False\n",
    "k_means = False\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "if hide_noise:\n",
    "    ax.scatter(\n",
    "        X[cluster.labels_ != -1][0],\n",
    "        X[cluster.labels_ != -1][1], \n",
    "        X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_[cluster.labels_ != -1], \n",
    "        cmap='flag')\n",
    "else:\n",
    "    ax.scatter(\n",
    "        X[0],\n",
    "        X[1], \n",
    "        X[2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_, \n",
    "        cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=10\n",
    "n_clusters=7\n",
    "hide_noise = True\n",
    "remove_noise = False\n",
    "k_means = False\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "if hide_noise:\n",
    "    ax.scatter(\n",
    "        X[cluster.labels_ != -1][0],\n",
    "        X[cluster.labels_ != -1][1], \n",
    "        X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_[cluster.labels_ != -1], \n",
    "        cmap='flag')\n",
    "else:\n",
    "    ax.scatter(\n",
    "        X[0],\n",
    "        X[1], \n",
    "        X[2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_, \n",
    "        cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=100\n",
    "n_clusters=7\n",
    "hide_noise = True\n",
    "remove_noise = False\n",
    "k_means = False\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "if hide_noise:\n",
    "    ax.scatter(\n",
    "        X[cluster.labels_ != -1][0],\n",
    "        X[cluster.labels_ != -1][1], \n",
    "        X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_[cluster.labels_ != -1], \n",
    "        cmap='flag')\n",
    "else:\n",
    "    ax.scatter(\n",
    "        X[0],\n",
    "        X[1], \n",
    "        X[2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_, \n",
    "        cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=20\n",
    "n_clusters=7\n",
    "hide_noise = True\n",
    "remove_noise = False\n",
    "k_means = False\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "if hide_noise:\n",
    "    ax.scatter(\n",
    "        X[cluster.labels_ != -1][0],\n",
    "        X[cluster.labels_ != -1][1], \n",
    "        X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_[cluster.labels_ != -1], \n",
    "        cmap='flag')\n",
    "else:\n",
    "    ax.scatter(\n",
    "        X[0],\n",
    "        X[1], \n",
    "        X[2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_, \n",
    "        cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=20\n",
    "n_clusters=7\n",
    "hide_noise = True\n",
    "remove_noise = False\n",
    "k_means = False\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "if hide_noise:\n",
    "    ax.scatter(\n",
    "        X[cluster.labels_ != -1][0],\n",
    "        X[cluster.labels_ != -1][1], \n",
    "        X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_[cluster.labels_ != -1], \n",
    "        cmap='rainbow')\n",
    "else:\n",
    "    ax.scatter(\n",
    "        X[0],\n",
    "        X[1], \n",
    "        X[2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_, \n",
    "        cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=5\n",
    "n_clusters=7\n",
    "hide_noise = True\n",
    "remove_noise = False\n",
    "k_means = False\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "if hide_noise:\n",
    "    ax.scatter(\n",
    "        X[cluster.labels_ != -1][0],\n",
    "        X[cluster.labels_ != -1][1], \n",
    "        X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_[cluster.labels_ != -1], \n",
    "        cmap='rainbow')\n",
    "else:\n",
    "    ax.scatter(\n",
    "        X[0],\n",
    "        X[1], \n",
    "        X[2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_, \n",
    "        cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=8\n",
    "n_clusters=7\n",
    "hide_noise = True\n",
    "remove_noise = False\n",
    "k_means = False\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "if hide_noise:\n",
    "    ax.scatter(\n",
    "        X[cluster.labels_ != -1][0],\n",
    "        X[cluster.labels_ != -1][1], \n",
    "        X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_[cluster.labels_ != -1], \n",
    "        cmap='rainbow')\n",
    "else:\n",
    "    ax.scatter(\n",
    "        X[0],\n",
    "        X[1], \n",
    "        X[2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_, \n",
    "        cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=8\n",
    "n_clusters=7\n",
    "hide_noise = False\n",
    "remove_noise = False\n",
    "k_means = False\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "if hide_noise:\n",
    "    ax.scatter(\n",
    "        X[cluster.labels_ != -1][0],\n",
    "        X[cluster.labels_ != -1][1], \n",
    "        X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_[cluster.labels_ != -1], \n",
    "        cmap='rainbow')\n",
    "else:\n",
    "    ax.scatter(\n",
    "        X[0],\n",
    "        X[1], \n",
    "        X[2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_, \n",
    "        cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=10\n",
    "n_clusters=7\n",
    "hide_noise = False\n",
    "remove_noise = False\n",
    "k_means = False\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "if hide_noise:\n",
    "    ax.scatter(\n",
    "        X[cluster.labels_ != -1][0],\n",
    "        X[cluster.labels_ != -1][1], \n",
    "        X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_[cluster.labels_ != -1], \n",
    "        cmap='rainbow')\n",
    "else:\n",
    "    ax.scatter(\n",
    "        X[0],\n",
    "        X[1], \n",
    "        X[2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_, \n",
    "        cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=9\n",
    "n_clusters=7\n",
    "hide_noise = False\n",
    "remove_noise = False\n",
    "k_means = False\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "if hide_noise:\n",
    "    ax.scatter(\n",
    "        X[cluster.labels_ != -1][0],\n",
    "        X[cluster.labels_ != -1][1], \n",
    "        X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_[cluster.labels_ != -1], \n",
    "        cmap='rainbow')\n",
    "else:\n",
    "    ax.scatter(\n",
    "        X[0],\n",
    "        X[1], \n",
    "        X[2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_, \n",
    "        cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=8\n",
    "n_clusters=7\n",
    "hide_noise = False\n",
    "remove_noise = False\n",
    "k_means = False\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "if hide_noise:\n",
    "    ax.scatter(\n",
    "        X[cluster.labels_ != -1][0],\n",
    "        X[cluster.labels_ != -1][1], \n",
    "        X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_[cluster.labels_ != -1], \n",
    "        cmap='rainbow')\n",
    "else:\n",
    "    ax.scatter(\n",
    "        X[0],\n",
    "        X[1], \n",
    "        X[2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_, \n",
    "        cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=9\n",
    "n_clusters=7\n",
    "hide_noise = False\n",
    "remove_noise = False\n",
    "k_means = False\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "if hide_noise:\n",
    "    ax.scatter(\n",
    "        X[cluster.labels_ != -1][0],\n",
    "        X[cluster.labels_ != -1][1], \n",
    "        X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_[cluster.labels_ != -1], \n",
    "        cmap='rainbow')\n",
    "else:\n",
    "    ax.scatter(\n",
    "        X[0],\n",
    "        X[1], \n",
    "        X[2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_, \n",
    "        cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=10\n",
    "n_clusters=7\n",
    "hide_noise = False\n",
    "remove_noise = False\n",
    "k_means = False\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "if hide_noise:\n",
    "    ax.scatter(\n",
    "        X[cluster.labels_ != -1][0],\n",
    "        X[cluster.labels_ != -1][1], \n",
    "        X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_[cluster.labels_ != -1], \n",
    "        cmap='rainbow')\n",
    "else:\n",
    "    ax.scatter(\n",
    "        X[0],\n",
    "        X[1], \n",
    "        X[2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_, \n",
    "        cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=11\n",
    "n_clusters=7\n",
    "hide_noise = False\n",
    "remove_noise = False\n",
    "k_means = False\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "if hide_noise:\n",
    "    ax.scatter(\n",
    "        X[cluster.labels_ != -1][0],\n",
    "        X[cluster.labels_ != -1][1], \n",
    "        X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_[cluster.labels_ != -1], \n",
    "        cmap='rainbow')\n",
    "else:\n",
    "    ax.scatter(\n",
    "        X[0],\n",
    "        X[1], \n",
    "        X[2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_, \n",
    "        cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=15\n",
    "n_clusters=7\n",
    "hide_noise = False\n",
    "remove_noise = False\n",
    "k_means = False\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "if hide_noise:\n",
    "    ax.scatter(\n",
    "        X[cluster.labels_ != -1][0],\n",
    "        X[cluster.labels_ != -1][1], \n",
    "        X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_[cluster.labels_ != -1], \n",
    "        cmap='rainbow')\n",
    "else:\n",
    "    ax.scatter(\n",
    "        X[0],\n",
    "        X[1], \n",
    "        X[2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_, \n",
    "        cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=8\n",
    "n_clusters=7\n",
    "hide_noise = False\n",
    "remove_noise = False\n",
    "k_means = False\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "if hide_noise:\n",
    "    ax.scatter(\n",
    "        X[cluster.labels_ != -1][0],\n",
    "        X[cluster.labels_ != -1][1], \n",
    "        X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_[cluster.labels_ != -1], \n",
    "        cmap='rainbow')\n",
    "else:\n",
    "    ax.scatter(\n",
    "        X[0],\n",
    "        X[1], \n",
    "        X[2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_, \n",
    "        cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=9\n",
    "n_clusters=7\n",
    "hide_noise = False\n",
    "remove_noise = False\n",
    "k_means = False\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "if hide_noise:\n",
    "    ax.scatter(\n",
    "        X[cluster.labels_ != -1][0],\n",
    "        X[cluster.labels_ != -1][1], \n",
    "        X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_[cluster.labels_ != -1], \n",
    "        cmap='rainbow')\n",
    "else:\n",
    "    ax.scatter(\n",
    "        X[0],\n",
    "        X[1], \n",
    "        X[2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_, \n",
    "        cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=10\n",
    "n_clusters=7\n",
    "hide_noise = False\n",
    "remove_noise = False\n",
    "k_means = False\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "if hide_noise:\n",
    "    ax.scatter(\n",
    "        X[cluster.labels_ != -1][0],\n",
    "        X[cluster.labels_ != -1][1], \n",
    "        X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_[cluster.labels_ != -1], \n",
    "        cmap='rainbow')\n",
    "else:\n",
    "    ax.scatter(\n",
    "        X[0],\n",
    "        X[1], \n",
    "        X[2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_, \n",
    "        cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=10\n",
    "n_clusters=7\n",
    "hide_noise = False\n",
    "remove_noise = True\n",
    "k_means = True\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "if hide_noise:\n",
    "    ax.scatter(\n",
    "        X[cluster.labels_ != -1][0],\n",
    "        X[cluster.labels_ != -1][1], \n",
    "        X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_[cluster.labels_ != -1], \n",
    "        cmap='rainbow')\n",
    "else:\n",
    "    ax.scatter(\n",
    "        X[0],\n",
    "        X[1], \n",
    "        X[2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_, \n",
    "        cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=10\n",
    "n_clusters=6\n",
    "hide_noise = False\n",
    "remove_noise = False\n",
    "k_means = True\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=2)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "if hide_noise:\n",
    "    ax.scatter(\n",
    "        X[cluster.labels_ != -1][0],\n",
    "        X[cluster.labels_ != -1][1], \n",
    "        X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_[cluster.labels_ != -1], \n",
    "        cmap='rainbow')\n",
    "else:\n",
    "    ax.scatter(\n",
    "        X[0],\n",
    "        X[1], \n",
    "        X[2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_, \n",
    "        cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=10\n",
    "n_clusters=6\n",
    "hide_noise = False\n",
    "remove_noise = False\n",
    "k_means = True\n",
    "\n",
    "if remove_noise:\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    \n",
    "    X_w_noise = X\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=1)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "#     cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "#     cluster.fit_predict(X) \n",
    "\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "if hide_noise:\n",
    "    ax.scatter(\n",
    "        X[cluster.labels_ != -1][0],\n",
    "        X[cluster.labels_ != -1][1], \n",
    "        X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_[cluster.labels_ != -1], \n",
    "        cmap='rainbow')\n",
    "else:\n",
    "    ax.scatter(\n",
    "        X[0],\n",
    "        X[1], \n",
    "        X[2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_, \n",
    "        cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if k_means:\n",
    "    for i, center in enumerate(cluster.cluster_centers_):\n",
    "        ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "if k_means:\n",
    "    for c, center in enumerate(cluster.cluster_centers_):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "        pp({\"cluster\": c, \"cells\": X.iloc[dist_sort_is].index[:5], \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_w_labels = DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"CLuster\"] = cluster.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_w_noise.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_w_noise[\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_w_noise[\"Cluster\"] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_w_noise[\"Cluster\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_w_noise.loc[X.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_w_noise.loc[X.index]['Cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_w_noise.loc[X.index]['Cluster']=cluster.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_w_noise.loc[X.index]['Cluster']#=cluster.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_w_noise.loc[X.index]['Cluster']#=cluster.labels_\n",
    "\n",
    "for label in X.index:\n",
    "    X_w_noise.at[label, \"Cluster\"] = X.at[label, \"CLuster\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_w_noise.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_w_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_w_noise[\"Cluster\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(X_w_noise[\"Cluster\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_w_noise[\"Cluster\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[\"Cluster\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Cluster\"] = X_w_noise[\"Cluster\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set subset df cluster\n",
    "#df[\"Cluster\"] = cluster.labels_\n",
    "\n",
    "df[\"ClusterPath\"] = df[\"ClusterPath\"] + df[\"Cluster\"].map(str) + \"/\"\n",
    "\n",
    "for label in df.index:\n",
    "    df_all.at[label, \"ClusterPath\"] = df.at[label, \"ClusterPath\"]\n",
    "    df_all.at[label, \"Cluster\"] = df.at[label, \"Cluster\"]\n",
    "\n",
    "df.head()[\"ClusterPath\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(df_all.head()[\"ClusterPath\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(df_all[\"ClusterPath\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"ClusterPath\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_records = list(Cells\\\n",
    "    .select(Cells,Model_Waveforms.Spikes,Models.Name)\\\n",
    "    .join(Model_Waveforms, on=(Cells.Model_ID == Model_Waveforms.Model_id))\\\n",
    "    .join(Models, on=(Cells.Model_ID == Models.Model_ID))\\\n",
    "    .where((Model_Waveforms.Protocol == \"STEADY_STATE\") & (Model_Waveforms.Variable_Name == \"Voltage\"))\\\n",
    "    .order_by(Cells.Model_ID)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"NMLCL00001\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"NMLCL000001\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[:,\"NMLCL000001\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.iloc[\"NMLCL000001\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.loc[\"NMLCL000001\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.loc[\"NMLCL000001\"][\"ClusterPath\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.loc[\"NMLCL000086\"][\"ClusterPath\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.loc[\"NMLCL001416\"][\"ClusterPath\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.loc[\"NMLCL001124\"][\"ClusterPath\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell_id in df_all.index:\n",
    "    cell = next(cell for cell in cell_records if cell.Model_ID == cell_id)\n",
    "    cell.ClusterPath = df_all.loc[\"NMLCL000001\"][\"ClusterPath\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "[cell for cell in cell_records]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "[cell.ClusterPath for cell in cell_records]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique([cell.ClusterPath for cell in cell_records])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"ClusterPath\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell_id in df_all.index:\n",
    "    cell = next(cell for cell in cell_records if cell.Model_ID == cell_id)\n",
    "    cell.ClusterPath = df_all.loc[cell_id][\"ClusterPath\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique([cell.ClusterPath for cell in cell_records])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell_id in df_all.index:\n",
    "    cell = next(cell for cell in cell_records if cell.Model_ID == cell_id)\n",
    "    cell.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cols = [\"ISIMedian\"]\n",
    "\n",
    "for cl in range(6):\n",
    "    print(\"Cluster\", cl)\n",
    "    cl4 = np.where(cluster.labels_ == cl)\n",
    "    cl4_data = X.iloc[cl4]\n",
    "    \n",
    "    cl4_data.columns = [\"PC\" + str(c) for c in cl4_data.columns]\n",
    "    cl4_raw = df_all.loc[cl4_data.index]\n",
    "    \n",
    "    \n",
    "    for col in cols:\n",
    "        plt.scatter(cl4_raw[\"AP1DelayMean\"], cl4_raw[col]); plt.show();\n",
    "        print(\"AP1DelayMean\",col,pearsonr(cl4_raw[\"AP1DelayMean\"], cl4_raw[col]))\n",
    "        print(smf.ols('AP1DelayMean~'+col,data=cl4_raw).fit().summary())\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "cols = [\n",
    "\"PC2\",\n",
    "#\"PC0\"\n",
    "]\n",
    "\n",
    "for cl in range(6):\n",
    "    print(\"Cluster\", cl)\n",
    "    cl4 = np.where(cluster.labels_ == cl)\n",
    "    cl4_data = X.iloc[cl4]\n",
    "    \n",
    "    cl4_data.columns = [\"PC\" + str(c) for c in cl4_data.columns]\n",
    "    cl4_raw = df_all.loc[cl4_data.index]\n",
    "    \n",
    "    \n",
    "    for col in cols:\n",
    "        corr = pearsonr(cl4_data[\"PC1\"], cl4_data[col])\n",
    "        print(\"PC1\",col,corr[0],corr[1] < 0.001)\n",
    "        print(smf.ols('PC1~'+col,data=cl4_data).fit().summary())\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from manager import ModelManager\n",
    "from tables import Cells, Model_Waveforms, Models\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import pandas\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "import statsmodels.formula.api as smf\n",
    "import hdbscan\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "pandas.set_option('display.max_columns', None)\n",
    "pandas.set_option('display.max_rows', 20)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
